{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import re\n",
    "import os\n",
    "\n",
    "def create_json_from_markdown(markdown_path, output_filename=\"request.json\"):\n",
    "    \"\"\"\n",
    "    Parses a markdown file to create a JSON request for a journal entry.\n",
    "\n",
    "    Args:\n",
    "        markdown_path (str): The file path to the markdown journal entry.\n",
    "        output_filename (str): The name of the output JSON file.\n",
    "    \"\"\"\n",
    "    # --- 1. Read and Parse the Markdown File ---\n",
    "    try:\n",
    "        with open(markdown_path, 'r') as md_file:\n",
    "            lines = md_file.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{markdown_path}' was not found.\")\n",
    "        return\n",
    "\n",
    "    title = \"\"\n",
    "    paragraphs = []\n",
    "    images_to_process = []\n",
    "    current_paragraph = \"\"\n",
    "\n",
    "    # Regular expression to find markdown image tags\n",
    "    image_regex = re.compile(r'!\\[.*\\]\\((.*?)\\)')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Find title\n",
    "        if line.startswith('### '):\n",
    "            title = line[4:].strip()\n",
    "            continue\n",
    "\n",
    "        # Find image\n",
    "        image_match = image_regex.match(line)\n",
    "        if image_match:\n",
    "            # When an image is found, if there's a current paragraph, add it to the list\n",
    "            if current_paragraph:\n",
    "                paragraphs.append(current_paragraph)\n",
    "                current_paragraph = \"\"\n",
    "            \n",
    "            image_path = image_match.group(1)\n",
    "            # The position is after the last paragraph found (0-indexed)\n",
    "            position = len(paragraphs) - 1\n",
    "            images_to_process.append({\"path\": image_path, \"position\": position})\n",
    "            continue\n",
    "\n",
    "        # Collate paragraphs\n",
    "        if line:\n",
    "            current_paragraph += line + \" \"\n",
    "        elif current_paragraph:\n",
    "            # A blank line signifies the end of a paragraph\n",
    "            paragraphs.append(current_paragraph.strip())\n",
    "            current_paragraph = \"\"\n",
    "    \n",
    "    # Add any remaining paragraph\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(current_paragraph.strip())\n",
    "\n",
    "    # The full text is all paragraphs joined together\n",
    "    full_text = \"\\n\\n\".join(paragraphs)\n",
    "\n",
    "    # --- 2. Process and Encode Images ---\n",
    "    processed_images = []\n",
    "    for image_info in images_to_process:\n",
    "        image_path = image_info[\"path\"]\n",
    "        try:\n",
    "            image_format = image_path.split('.')[-1]\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                base64_bytes = base64.b64encode(image_file.read())\n",
    "                encoded_image_string = base64_bytes.decode('utf-8')\n",
    "            \n",
    "            processed_images.append({\n",
    "                \"encoding\": \"base64\",\n",
    "                \"format\": image_format,\n",
    "                \"content\": encoded_image_string,\n",
    "                \"position_after_paragraph\": image_info[\"position\"]\n",
    "            })\n",
    "            print(f\"Successfully encoded '{image_path}' to be placed after paragraph {image_info['position']}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Image file '{image_path}' not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred encoding '{image_path}': {e}\")\n",
    "            \n",
    "    # --- 3. Structure and Write the JSON File ---\n",
    "    request_data = {\n",
    "        \"entry_data\": {\n",
    "            \"title\": title,\n",
    "            \"text\": full_text,\n",
    "        },\n",
    "        \"media_context\": {\n",
    "            \"video_emotion\": \"happy\", # Example value\n",
    "            \"video_emotion_confidence\": 0.955, # Example value\n",
    "            \"images\": processed_images\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(output_filename, 'w') as json_file:\n",
    "            json.dump(request_data, json_file, indent=2)\n",
    "        print(f\"\\nSuccessfully created '{output_filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while writing the JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_file_to_parse = \"journal.md\"\n",
    "create_json_from_markdown(markdown_file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image_from_response(file_path: str):\n",
    "    \"\"\"\n",
    "    Reads a JSON response file, decodes a base64 image,\n",
    "    and displays it using matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Open and read the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        response_data = json.load(f)\n",
    "\n",
    "    # 2. Extract the base64 string from the 'images' list\n",
    "    if not response_data.get('images'):\n",
    "        print(\"Error: No 'images' key found in the JSON file.\")\n",
    "        return\n",
    "        \n",
    "    base64_image_str = response_data['images'][0]\n",
    "\n",
    "    # 3. Decode the base64 string into bytes\n",
    "    image_bytes = base64.b64decode(base64_image_str)\n",
    "\n",
    "    # 4. Create an in-memory byte stream and open it as an image\n",
    "    image_file = io.BytesIO(image_bytes)\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    # 5. Plot the image using matplotlib\n",
    "    print(f\"Displaying image from prompt: \\\"{response_data.get('prompt', 'N/A')}\\\"\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide the axes for a cleaner look\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "json_file_path = 'response.json'\n",
    "display_image_from_response(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"user_id\": \"user-uuid\",\n",
    "  \"journal_data\": {\n",
    "    \"text\": \"The full, multi-paragraph text of the user's first draft.\",\n",
    "    \"user_images\": [\n",
    "      {\n",
    "        \"encoding\": \"base64\",\n",
    "        \"format\": \"png\",\n",
    "        \"content\": \"base64_string_of_user_image...\",\n",
    "        \"position_after_paragraph\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output schema\n",
    "{\n",
    "  \"conversation_id\": \"string\",\n",
    "  \"suggestion\": {\n",
    "    \"strategy_used\": \"string\",\n",
    "    \"suggestion_text\": \"string\",\n",
    "    \"highlight_text\": \"string\"\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ed676",
   "metadata": {},
   "source": [
    "### **Project Brief: AI Journaling Chatbot Implementation (Unified Endpoint)**\n",
    "\n",
    "**To the Coder LLM:**\n",
    "You are an expert Python developer specializing in FastAPI and AI applications. Your task is to implement the backend logic for a sophisticated chatbot feature for a smart journaling application using a **single, unified endpoint**. The chatbot acts as an \"Elaboration Coach\" to help enrich writing and as a \"Compassionate Listener\" for follow-up conversation.\n",
    "\n",
    "Please use the following detailed specification to generate the Python code. The primary framework is **FastAPI** to handle the request and langchain to handle the interaction with the LLM. LLM used is openAI model. All history (journal drafts, chat messages) is stored on the backend with the help of langchain, associated with a `uuid`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. High-Level Goal & Chatbot Persona**\n",
    "\n",
    "* **Goal:** To create an AI assistant that encourages users to write richer, more detailed journal entries and reflect more deeply on their experiences.\n",
    "* **Persona: \"The Compassionate Listener & Elaboration Coach\"**.\n",
    "    * **Tone:** Gentle, curious, validating, and supportive.\n",
    "    * **Core Directives:** It never gives advice. It asks open-ended questions. It uses the journal's context to be relevant. It preserves the user's original voice.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Unified API Endpoint Design & Schemas**\n",
    "\n",
    "A single endpoint will handle all interactions. The backend will determine the user's intent based on the presence of optional fields in the request.\n",
    "\n",
    "* **Endpoint:** `POST /elaboration-chat`\n",
    "* **Request Body Schema:**\n",
    "    ```json\n",
    "    {\n",
    "      \"uuid\": \"string\",\n",
    "      \"journal_data\": {\n",
    "        \"text\": \"string\",\n",
    "        \"user_images\": [\n",
    "          {\n",
    "            \"encoding\": \"base64\",\n",
    "            \"format\": \"png\",\n",
    "            \"content\": \"string\",\n",
    "            \"position_after_paragraph\": \"integer\"\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"user_chat_input\": \"string\"\n",
    "    }\n",
    "    ```\n",
    "    * **`uuid` (string, required):** The unique session/journal identifier.\n",
    "    * **`journal_data` (object, optional):** Present for the initial request or when the user has modified the journal text.\n",
    "    * **`user_chat_input` (string, optional):** Present when the user is sending a conversational message to the chatbot.\n",
    "\n",
    "* **Response Body Schema:**\n",
    "    ```json\n",
    "    {\n",
    "      \"uuid\": \"string\",\n",
    "      \"elaboration_suggestion\": {\n",
    "        \"strategy_used\": \"string\",\n",
    "        \"suggestion_text\": \"string\",\n",
    "        \"highlight_text\": \"string\"\n",
    "      },\n",
    "      \"assistant_response\": \"string\",\n",
    "      \"is_final_message\": \"boolean\"\n",
    "    }\n",
    "    ```\n",
    "    * **`uuid` (string, required):** The session identifier, returned for confirmation.\n",
    "    * **`elaboration_suggestion` (object, optional):** The coaching prompt. This is the primary response when the user provides `journal_data`. It is `null` otherwise.\n",
    "    * **`assistant_response` (string, optional):** The chatbot's conversational reply. This is the primary response when the user provides `user_chat_input`. It is `null` otherwise.\n",
    "    * **`is_final_message` (boolean, required):** Signals to the client if the conversation is considered complete.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Core AI Logic & LLM Prompts**\n",
    "\n",
    "##### **Logic for Analyzing Journal Content (The \"Elaboration Coach\")**\n",
    "\n",
    "* **System Instruction:**\n",
    "    > You are an AI Literary Analyst. Your function is to analyze a journal entry and identify the single best paragraph for elaboration. Evaluate each paragraph based on: 1. Visual Richness, 2. Emotional Significance, 3. Narrative Core. You MUST respond with a JSON object containing the `illustratable_paragraphs` as an array of the top 1-4 paragraph indices (based on 40% of total paragraphs).\n",
    "\n",
    "##### **Logic for Continuous Chat (The \"Compassionate Listener\")**\n",
    "\n",
    "* **System Instruction:**\n",
    "    > You are \"Echo,\" a compassionate and insightful journaling assistant. Your ONLY goal is to ask ONE gentle, open-ended follow-up question or provide a validating concluding remark. **RULES:** DO NOT offer advice. DO NOT share opinions. DO NOT use toxic positivity. Use the provided full session history for context.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Unified Endpoint Logic & Workflow**\n",
    "\n",
    "The backend logic for the single `POST /elaboration-chat` endpoint follows this decision tree:\n",
    "\n",
    "1.  Receive the request containing `uuid` and optional `journal_data` and/or `user_chat_input`.\n",
    "2.  Load the complete session history for the given `uuid` from the backend's state store (e.g., in-memory dictionary, Redis). The history contains all previous journal text versions and all chat messages.\n",
    "\n",
    "3.  **Execute one of the following branches:**\n",
    "\n",
    "    * **A) IF `journal_data` has content (covers user actions 1, 2, and 4):**\n",
    "        * This is the priority action. The user has written or edited their journal.\n",
    "        * Update the session history with the new `journal_data.text`.\n",
    "        * Execute the **\"Elaboration Coach\"** logic on the new text.\n",
    "        * Generate an `elaboration_suggestion` (or `null` if the entry is complete).\n",
    "        * Construct the response with the `elaboration_suggestion` and `assistant_response: null`.\n",
    "\n",
    "    * **B) ELSE IF `user_chat_input` has content (covers user action 3):**\n",
    "        * The user is having a conversation.\n",
    "        * Append the `user_chat_input` to the chat history.\n",
    "        * Execute the **\"Compassionate Listener\"** logic using the full session history.\n",
    "        * Generate an `assistant_response` and determine if it's a final message.\n",
    "        * Construct the response with the `assistant_response` and `elaboration_suggestion: null`.\n",
    "\n",
    "4.  Save the updated session history (new text and/or new chat messages) back to the state store associated with the `uuid`.\n",
    "5.  Return the constructed JSON response to the client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7cab2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3043d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting code extraction from '../'...\n",
      "Processing: extract.py\n",
      "Processing: app\\__init__.py\n",
      "Processing: app\\config.py\n",
      "Processing: app\\dependencies.py\n",
      "Processing: app\\main.py\n",
      "Processing: app\\schemas.py\n",
      "Processing: app\\logutils\\__init__.py\n",
      "Processing: app\\logutils\\logger.py\n",
      "Processing: app\\services\\__init__.py\n",
      "Processing: app\\services\\classification_service.py\n",
      "Processing: app\\services\\elaboration_service.py\n",
      "Processing: app\\services\\embedding_service.py\n",
      "Processing: app\\services\\illustration_service.py\n",
      "Processing: app\\services\\model_provider.py\n",
      "Processing: app\\services\\session_service.py\n",
      "Processing: app\\services\\vlm_service.py\n",
      "\n",
      "✅ Successfully generated 'codebase_summary.md'!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_python_code_to_markdown(root_dir, output_file):\n",
    "    \"\"\"\n",
    "    Walks through a directory, finds all Python (.py) files,\n",
    "    extracts their content, and compiles them into a single\n",
    "    Markdown file.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The path to the root directory of the project.\n",
    "        output_file (str): The name of the markdown file to be created.\n",
    "    \"\"\"\n",
    "    # Excluded directories\n",
    "    excluded_dirs = {'__pycache__', '.venv', 'venv', 'env'}\n",
    "\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as md_file:\n",
    "            md_file.write(\"# Project Codebase Summary\\n\\n\")\n",
    "            print(f\"Starting code extraction from '{root_dir}'...\")\n",
    "\n",
    "            # Walk through the directory structure\n",
    "            for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "                # Modify dirnames in-place to skip excluded directories\n",
    "                dirnames[:] = [d for d in dirnames if d not in excluded_dirs]\n",
    "\n",
    "                # Sort filenames to maintain a consistent order\n",
    "                for filename in sorted(filenames):\n",
    "                    if filename.endswith('.py'):\n",
    "                        file_path = os.path.join(dirpath, filename)\n",
    "                        # Create a relative path for cleaner output\n",
    "                        relative_path = os.path.relpath(file_path, root_dir)\n",
    "\n",
    "                        print(f\"Processing: {relative_path}\")\n",
    "\n",
    "                        # Write a separator and the file path as a header\n",
    "                        md_file.write(f\"---\\n\\n\")\n",
    "                        md_file.write(f\"## File: `{relative_path}`\\n\\n\")\n",
    "                        md_file.write(\"```python\\n\")\n",
    "\n",
    "                        try:\n",
    "                            with open(file_path, 'r', encoding='utf-8') as py_file:\n",
    "                                content = py_file.read()\n",
    "                                md_file.write(content)\n",
    "                        except Exception as e:\n",
    "                            md_file.write(f\"# Error reading file: {e}\\n\")\n",
    "\n",
    "                        md_file.write(\"\\n```\\n\\n\")\n",
    "\n",
    "        print(f\"\\n✅ Successfully generated '{output_file}'!\")\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"❌ Error: Could not write to file '{output_file}'. Reason: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "start_directory = '../'\n",
    "output_markdown_file = 'codebase_summary.md'\n",
    "extract_python_code_to_markdown(start_directory, output_markdown_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
